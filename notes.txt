

Ratubgs density metric
mean
median
standrad deviation
max min
for user and movie
total number of ratings for each fo the 5 ratings classes

I had to decide whether to work with double or int in my rate guessing. It didn't really come up until I wrapped up

I definitely DON'T have any sort of neighborhood system right now. Not really sure how to implement that.
Fuck this project



    private static Map<Integer, Person> makePersonMap(Rating[] rateList){
        Map<Integer, Person> personMap = new HashMap<>();
        //System.out.println("makePersonMap: start");
        for (int i = 0; i < rateList.length; i++) {
            int tempID = rateList[i].getPersonID();
            if(personMap.containsKey(tempID)){
                //System.out.println("makePersonMap: if");
                DuoMovie tempDuo = new DuoMovie(movieMap.get(rateList[i].getPersonID()),rateList[i].getRating());
                personMap.get(tempID).addMovie(rateList[i].getMovieID(),);
            }else{
                //System.out.println("makePersonMap: else");
                Person newP = new Person(tempID);
                newP.addMovie(rateList[i].getMovieID(),rateList[i].getRating());
                personMap.put(tempID, newP);
            }
        }
        //System.out.println("Person Map Size: " + personMap.size());
        return personMap;
    }

    private static Map<Integer, Movie> makeMovieMap(Rating[] rateList){
        System.out.println("Start makeMovieMap");
        Map<Integer, Movie> movieMap = new HashMap<>();
        int ifCount = 0;
        int elseCount = 0;
        for (int i = 0; i < rateList.length; i++) {
            //System.out.println("makeMovieMap: i = " + i);
            int tempID = rateList[i].getMovieID();
            if(movieMap.containsKey(tempID) == true){
                //System.out.println("makeMovieMap: if");
                ifCount++;
                movieMap.get(tempID).addPerson(rateList[i].getPersonID(),rateList[i].getRating());
            }else{
                //System.out.println("makeMovieMap: else");
                elseCount++;
                Movie newM = new Movie(tempID);
                newM.addPerson(rateList[i].getPersonID(),rateList[i].getRating());
                movieMap.put(tempID, newM);
            }
        }
        System.out.println("M ifCount = " + ifCount);
        System.out.println("M elseCount = " + elseCount);
        return movieMap;
    }




On to Task 3!
	Implement the distance-based user similarity metric discussed in lectures and use this as the basis for prediction*.
		If we want to pick one person and make a recommendation, then we generate a neighbor hood for them by picking out the movies they feel strongly about and pulling data from ppl who feel the same
		get all xPerson's rating.
        Stick em in a list.
        iterate thru the list
            pull out every other person that rated and put them in a list too
            the average difference between 2 users
            give every person a list of people that they have overlapped with
            just a simple hashmap of int to double
                int is the neighbor's id, double is the average difference between neighbor and ogUser
                everytime they intersect, update on both sides
                but then how to prevent overlap?
                keep a list of recorded overlaps 
                I'm gunna need a new class :(
	Experiment with different approaches for computing the target userâ€™s neighbourhood as the basis for this distance-based prediction; e.g. by varying neighbourhood size, minimum neighbor overlap, or other suitable parameters.
		.
	Run a series of L1O tests to evaluate the impact of neighbourhood construction on overall RMSE. For example, if you are varying the size of the neighbourhood (n) then you will generate different RMSE, coverage, efficiency (time) values for different values of n. Produce a results csv file (with rows user_id, item_id, actual rating, predicted rating, RMSE) for each tested value of n.
		.




Execution Time for L1O:
1572 ms
1566 ms
1671 ms
1638 ms
1619 ms
1583 ms
1601 ms
1578 ms
1606 ms
1617 ms
-------
16051/10
--------
1605 ms average execution time



Percent Coverage: 0.9370422021957903
Average Percent Error: 0.4321025979964676
Result List Size: 99859


If there is only one rating, leave one out test needs to be skipped

It finally works

the first id is 1

User ID, Item ID, rating, timestamp

Ratings Density:	
	user - item matrix
	basically not every user rates every item
	100 users, 100 items, 1000 ratings
	100 * 100 = 10,000 possible ratings

Coverage:
	look at any pair, remove rating, see if you can predict a rating
	Coverage is total number of items for which you can generate a prediction / total number of user item pairs